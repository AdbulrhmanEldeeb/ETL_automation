subreddit,title,selftext,author,id,permalink,url,created_utc,score,upvote_ratio,ups,downs,num_comments,total_awards_received,gilded,is_video,is_original_content,is_self,over_18,spoiler,link_flair_text,thumbnail,name
datascience,TIME-MOE: Billion-Scale Time Series Forecasting with Mixture-of-Experts,"**Time-MOE** is a 2.4B parameter open-source time-series foundation model using **Mixture-of-Experts (MOE)** for zero-shot forecasting.

You can find an analysis of the model [here](https://aihorizonforecast.substack.com/p/time-moe-billion-scale-time-series)",nkafr,1h3hxe4,https://reddit.com/r/datascience/comments/1h3hxe4/timemoe_billionscale_time_series_forecasting_with/,https://www.reddit.com/r/datascience/comments/1h3hxe4/timemoe_billionscale_time_series_forecasting_with/,2024-11-30 17:43:23,38,0.88,38,0,13,0,0,False,False,True,False,False,Analysis,self,t3_1h3hxe4
datascience,Daily averaged time series comparison -Linking plankton and aerosols emissions?,"Hi everyone, so we have this dataset of daily averaged pytoplankton time series over a full year; coccolithophores, chlorophytes, cyanobacteria, diatoms, dinoflagellates, phaecocystis, zooplankton.  
Then we have atmospheric measurements on the same time intervals of a few aerosols species; Methanesulphonic acid, carboxylic acids, aliphatics, sulphates, ammonium, nitrates etc...  
Our goal is to establish all the possible links between plankton types and aerosols, we want to find out which planktons matter the most for a given aerosols species.

So here is my question; Which mathematical tools would you use to build a model with these (nonlinear) time series? Random Forest, cross-wavelets, transfer entropy, fractals analysis, chaos theory, Bayesian statistics? The thing that puzzle me most is that we know there is a lag between the plankton bloom and aerosols eventually forming in the atmosphere, it can take weeks for a bloom to trigger aerosols formation, so far many studies have just used lagged Pearson´s correlation, which I am not too happy with as correlation really isn´t reliable, would you know of any advanced methods to find out the optimal lag? What would be the best approach in your opinion?  
I would really appreciate any ideas, so please don´t hesitate to write down yours and I´d be happy to debate it, have a nice Sunday, cheers :)",Pleromakhos,1h4080y,https://reddit.com/r/datascience/comments/1h4080y/daily_averaged_time_series_comparison_linking/,https://www.reddit.com/r/datascience/comments/1h4080y/daily_averaged_time_series_comparison_linking/,2024-12-01 10:08:42,8,1.0,8,0,3,0,0,False,False,True,False,False,Discussion,self,t3_1h4080y
datascience,"Large scale video processing help
","I want to extract CLIP embeddings from 40k videos at a certain frame rate. To do this there are three main things I need to do, which are to first read the video to extract frames, preprocess the frames using the CLIP Image processor and use CLIP itself to extract the embeddings. The first two operations are cpu heavy and the last one is gpu heavy.

One option to do this would be to use Spark with a cluster of T4 machines, with more cores and RAM, that reads a chunk of the video, preprocesses it and encodes it using CLIP. But if I was to do that sometimes the GPU would be idle and sometimes the CPU would not be used to it's full potential.

What would be the best way to solve this issue? Note that if I was to split this into two tasks I would need to store the preprocessed video frames and that seems overkill because it be around 100 TB of storage (yeah, mp4 really compresses videos well). Is there a way to do this processing using two different kinds of machines on the same cluster? One that is CPU and RAM heavy and one that has a GPU?

I'm sure this could be achieves with Kubernetes, but that seems overkill for this task. Is there an easy way to do this with Spark? Should this even be done with Spark? For context I am doing this in GCP and I really only have basic knowledge of Spark",AdministrativeRub484,1h3ez08,https://reddit.com/r/datascience/comments/1h3ez08/large_scale_video_processing_help/,https://www.reddit.com/r/datascience/comments/1h3ez08/large_scale_video_processing_help/,2024-11-30 15:31:13,5,0.86,5,0,3,0,0,False,False,True,False,False,Discussion,self,t3_1h3ez08
datascience,Feature creation out of two features.,"I have been working on a project that tried to identify interactions in variables. What is a good way to capture these interactions by creating features? 

What are good mathematical expressions to capture interaction beyond multiplication and division?  Do note i have nulls and i cannot change it.",Tarneks,1h44274,https://reddit.com/r/datascience/comments/1h44274/feature_creation_out_of_two_features/,https://www.reddit.com/r/datascience/comments/1h44274/feature_creation_out_of_two_features/,2024-12-01 14:09:40,2,1.0,2,0,4,0,0,False,False,True,False,False,Projects,self,t3_1h44274
